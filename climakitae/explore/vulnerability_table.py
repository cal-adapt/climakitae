import numpy as np
import pandas as pd
from climakitae.explore.vulnerability import cava_data
from climakitae.explore import warming_levels as WarmingLevels
from climakitae.core.data_interface import DataParameters
from climakitae.core.data_load import load
import contextlib
import io

loc_idx = 10
suppress_output = True

# Params dict
table_vars = {
    "Likely summer day high": {
        "variable": "Air Temperature at 2m",
        "metric_calc": "max",
        "season": "summer",
        "percentile": 50,
        "heat_idx_threshold": None,
        "one_in_x": None,
    },
    "Likely summer night low": {
        "variable": "Air Temperature at 2m",
        "metric_calc": "min",
        "season": "summer",
        "percentile": 50,
        "heat_idx_threshold": None,
        "one_in_x": None,
    },
    "Likely winter day high": {
        "variable": "Air Temperature at 2m",
        "metric_calc": "max",
        "season": "winter",
        "percentile": 50,
        "heat_idx_threshold": None,
        "one_in_x": None,
    },
    "Likely winter night low": {
        "variable": "Air Temperature at 2m",
        "metric_calc": "min",
        "season": "winter",
        "percentile": 50,
        "heat_idx_threshold": None,
        "one_in_x": None,
    },
    "1-in-2 year maximum": {
        "variable": "Air Temperature at 2m",
        "metric_calc": "max",
        "season": "all",
        "percentile": None,
        "heat_idx_threshold": None,
        "one_in_x": 2,
    },
    "1-in-10 year maximum": {
        "variable": "Air Temperature at 2m",
        "metric_calc": "max",
        "season": "all",
        "percentile": None,
        "heat_idx_threshold": None,
        "one_in_x": 10,
    },
    "1-in-10 year minimum": {
        "variable": "Air Temperature at 2m",
        "metric_calc": "min",
        "season": "all",
        "percentile": None,
        "heat_idx_threshold": None,
        "one_in_x": 10,
    },
    "High/Extreme Heat Index": {
        "variable": "NOAA Heat Index",
        "metric_calc": "max",
        "season": "all",
        "percentile": None,
        "heat_idx_threshold": 91,
        "one_in_x": None,
    },
}


def create_vul_table(example_locs):
    """
    Creates a vulnerability assessment table and exports the table to CSV.
    """
    # Create empty df and instantiate variables
    df = pd.DataFrame(columns=table_vars.keys())
    lat, lon = example_locs.iloc[loc_idx]  # Oakland teehee
    months_map = {"winter": [12, 1, 2], "summer": [6, 7, 8], "all": np.arange(1, 13)}
    warming_levels = [
        "0.0",
        "1.5",
        "2.0",
        "3.0",
        "4.0",
    ]  # 0.0 = Historical Period (1980-2010)

    # Create each column in the table, which is the historical period (1980-2010) and each WL (1.5, 2.0, 3.0, 4.0).
    for warming_level in warming_levels:

        metrics = []
        preloaded_data_by_season = {}

        if warming_level != "0.0":

            # Retrieving warming level data once for each season so that it's not repeated constantly
            wl = WarmingLevels()
            wl.wl_params.timescale = "hourly"
            wl.wl_params.downscaling_method = "Dynamical"
            # wl.wl_params.variable_type = "Derived Index" if variable == "NOAA Heat Index" else "Variable"
            wl.wl_params.variable_type = "Variable"
            wl.wl_params.variable = "Air Temperature at 2m"
            wl.wl_params.latitude = (lat - 0.02, lat + 0.02)
            wl.wl_params.longitude = (lon - 0.02, lon + 0.02)
            wl.wl_params.warming_levels = [
                warming_level
            ]  # Calvin- default, only allow for 1 warming level to be passed in.
            wl.wl_params.units = "degF"
            wl.wl_params.resolution = "3 km"
            wl.wl_params.anom = "No"  # Q: When do we want this anomaly to be 'Yes'?

            print(
                f"\nRetrieving all warming level data by season to be cached and used in `cava_data`...\n"
            )

            for season in months_map.keys():

                # Calculating warming levels by season
                wl.wl_params.months = months_map[season]

                print(
                    f"\nRetrieving warming level data for {warming_level}°C in season {season}...\n"
                )

                wl.calculate()

                # Appending data to cached data variable
                preloaded_data_by_season[season] = wl.sliced_data[warming_level]

        else:

            # Retrieving time-based data once for each season so that it's not repeated constantly
            selections = DataParameters()
            selections.data_type = "Gridded"
            selections.downscaling_method = "Dynamical"
            selections.scenario_historical = ["Historical Climate"]
            selections.scenario_ssp = ssp_data = ["SSP3-7.0"]
            selections.timescale = "hourly"
            selections.variable = "Air Temperature at 2m"
            selections.variable_type = "Variable"
            selections.latitude = (
                lat - 0.02,
                lat + 0.02,
            )
            selections.longitude = (lon - 0.02, lon + 0.02)
            selections.time_slice = (1980, 2010)
            selections.resolution = "3 km"
            selections.units = "degF"

            print(
                f"\nRetrieving all time-based data by season to be cached and used in `cava_data`...\n"
            )

            data = load(selections.retrieve(), progress_bar=True)

            for season in months_map.keys():

                # Appending data to cached data variable
                preloaded_data_by_season[season] = data.sel(
                    time=data.time.dt.month.isin(months_map[season])
                )

        # Calculate each variable in the table
        for key in table_vars:
            params = table_vars[key]

            wl_or_hist_str = (
                "Historical Period (1980-2010)"
                if warming_level == "0.0"
                else warming_level + "°C"
            )
            print(f"\nRetrieving {key} for Warming Level {wl_or_hist_str}...\n")

            # Suppress outputs of `cava_data` function
            if suppress_output:

                with contextlib.redirect_stdout(io.StringIO()):

                    data = cava_data(
                        example_locs.iloc[loc_idx : loc_idx + 1],
                        time_start_year=1980,  # For historical period
                        time_end_year=2010,  # For historical period
                        units="degF",
                        downscaling_method="Dynamical",  # default for now ## mandatory
                        approach="warming_level" if warming_level != "0.0" else "time",
                        warming_level=warming_level,
                        wrf_bc=False,
                        historical_data="Historical Climate",  # or "historical reconstruction"
                        ssp_data=["SSP3-7.0"],
                        variable=params[
                            "variable"
                        ],  ## mandatory, must eventually accept temp, precip, or heat index
                        metric_calc=params["metric_calc"],
                        heat_idx_threshold=params["heat_idx_threshold"],  # Heat index
                        one_in_x=params["one_in_x"],  # Thresholds tools freq. counts
                        percentile=params["percentile"],
                        season=params["season"],
                        export_method="None",  # off-ramp, full calculate, both
                        separate_files=True,  # Toggle to determine whether or not the user wants to separate climate variable information into separate files
                        file_format="NetCDF",
                        preloaded_data=preloaded_data_by_season,
                    )

            # Retrieve data and average across simulation dimension
            val = data[0].mean(dim="simulation").item()

            # Add val to metrics to be added into row
            metrics.append(val)

        # Create dictionary of values to be input into DataFrame
        df.loc[warming_level] = pd.Series(dict(zip(table_vars.keys(), metrics)))

    # Make slight modifications to DataFrame
    df = df.T.rename(columns={"0.0": "Hist. Period (1980-2010)"})

    # Write out dataframe
    df.to_csv(f"final_table_{loc_idx}.csv", index=False)

    return df
