{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb5860a-029b-46ad-adc4-cf8fa11895c6",
   "metadata": {},
   "source": [
    "# Climate Profiles 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009daff",
   "metadata": {},
   "source": [
    "### Step 0: Set-Up\n",
    "Import the [climakitae](https://github.com/cal-adapt/climakitae) library and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c38af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm.auto import tqdm  # Progress bar\n",
    "\n",
    "import climakitae as ck\n",
    "from climakitae.explore.standard_year_profile import get_climate_profile, export_profile_to_csv\n",
    "from climakitae.explore.typical_meteorological_year import TMY\n",
    "from climakitae.core.data_interface import (\n",
    "    get_data_options,\n",
    "    get_subsetting_options,\n",
    "    get_data,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7fe7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions needed for testing\n",
    "from climakitae.core.constants import UNSET\n",
    "from climakitae.core.paths import VARIABLE_DESCRIPTIONS_CSV_PATH\n",
    "from climakitae.explore.typical_meteorological_year import is_HadISD\n",
    "from climakitae.explore.standard_year_profile import (\n",
    "    _get_clean_standardyr_filename,\n",
    "    _check_stations,\n",
    "    _check_cached_area,\n",
    "    _check_lat_lon,\n",
    "    match_str_to_wl,\n",
    ")\n",
    "from climakitae.util.utils import read_csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"Air Temperature at 2m\"\n",
    "units = \"degF\"\n",
    "qtile = 0.5\n",
    "warming_levels = [1.5]\n",
    "no_delta = True\n",
    "\n",
    "# warming level window size\n",
    "valid_window = 5\n",
    "invalid_window_1 = 2\n",
    "invalid_window_2 = 5.5\n",
    "\n",
    "# station name options\n",
    "station_list = [\n",
    "    \"Sacramento Executive Airport (KSAC)\",\n",
    "    \"Santa Barbara Municipal Airport (KSBA)\",\n",
    "]\n",
    "station_name = [\"Sacramento Executive Airport (KSAC)\"]\n",
    "custom_name = [\"Custom Station Name\"]\n",
    "mixed_list = [\n",
    "    \"Custom Station Name\",\n",
    "    \"Santa Barbara Municipal Airport (KSBA)\",\n",
    "]\n",
    "custom_list = [\n",
    "    \"Custom Name 1\",\n",
    "    \"Custom Name 2\",\n",
    "]\n",
    "\n",
    "# lat lon\n",
    "latitude = 34.4041\n",
    "longitude = -121.5160\n",
    "\n",
    "# cached area\n",
    "area_name = \"Los Angeles County\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e5b34",
   "metadata": {},
   "source": [
    "### Integration Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6790f",
   "metadata": {},
   "source": [
    "Test filename construction only, with different profile selection settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec94b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_location_name(**kwargs):\n",
    "    # Get location string based on combination of location variables\n",
    "    func_list = [_check_cached_area, _check_lat_lon, _check_stations]\n",
    "    location_str = \"\"\n",
    "    for func in func_list:\n",
    "        location_str = func(location_str, **kwargs)\n",
    "\n",
    "    return location_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "903ba54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_selections = {\n",
    "    \"variable\": variable,\n",
    "    \"resolution\": \"3 km\",\n",
    "    \"q\": qtile,\n",
    "    \"warming_level\": warming_levels,\n",
    "    \"units\": units,\n",
    "    \"no_delta\": no_delta,\n",
    "    # Location options -- uncomment based on your desired location type\n",
    "    # \"stations\": mixed_list,  # uncomment for a weather station\n",
    "    \"latitude\": (\n",
    "        latitude - 0.02,\n",
    "        latitude + 0.02,\n",
    "    ),  # uncomment for a using a custom coordinate location\n",
    "    \"longitude\": (\n",
    "        longitude - 0.02,\n",
    "        longitude + 0.02,\n",
    "    ),  # uncomment for a custom coordinate location\n",
    "    # \"cached_area\": area_name, # uncomment for a cached area\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef39ca5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34-4041N_121-516W'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_location_name(**profile_selections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e44c0",
   "metadata": {},
   "source": [
    "Double Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd4e45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get required parameter values\n",
    "q = qtile\n",
    "global_warming_levels = warming_levels\n",
    "\n",
    "# Get variable id string to use in file name\n",
    "variable_descriptions = read_csv_file(VARIABLE_DESCRIPTIONS_CSV_PATH)\n",
    "var_id = variable_descriptions[\n",
    "    (variable_descriptions[\"display_name\"] == variable)\n",
    "    & (variable_descriptions[\"timescale\"] == \"hourly\")\n",
    "][\"variable_id\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66351c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_str = test_location_name(**profile_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "127e25a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stdyr_t2_50ptile_sacramento_executive_airport_ksac_santa_barbara_municipal_airport_ksba_near-future.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_clean_standardyr_filename(\n",
    "                var_id, q, location_str, global_warming_levels[0], no_delta\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdb3e4",
   "metadata": {},
   "source": [
    "### Helper Function Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e34aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cached_area(location_str,**kwargs):\n",
    "    return _check_cached_area(location_str, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0ff3791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'los angeles county'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cached_area(\"\",**profile_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efad32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lat_lon(location_str, **kwargs):\n",
    "    location_str = _check_cached_area(location_str,**kwargs)\n",
    "    return _check_lat_lon(location_str, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb6f20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sacramento executive airport (ksac)_santa barbara municipal airport (ksba)'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_selections = {\n",
    "    \"variable\": variable,\n",
    "    \"resolution\": \"3 km\",\n",
    "    \"q\": qtile,\n",
    "    \"warming_level\": warming_levels,\n",
    "    \"units\": units,\n",
    "    \"no_delta\": no_delta,\n",
    "    # Location options -- uncomment based on your desired location type\n",
    "    # \"stations\": station_list,  # uncomment for a weather station\n",
    "    \"latitude\": (\n",
    "        latitude - 0.02,\n",
    "        latitude + 0.02,\n",
    "    ),  # uncomment for a using a custom coordinate location\n",
    "    \"longitude\": (\n",
    "        longitude - 0.02,\n",
    "        longitude + 0.02,\n",
    "    ),  # uncomment for a custom coordinate location\n",
    "    # \"cached_area\": area_name, # uncomment for a cached area\n",
    "}\n",
    "\n",
    "location_str = \"\"\n",
    "\n",
    "test_lat_lon(location_str, **profile_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "010744ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'los angeles county'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lat_lon(location_str, **profile_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59a61a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stations(location_str, **kwargs):\n",
    "    location_str = _check_cached_area(location_str, **kwargs)\n",
    "    location_str = _check_lat_lon(location_str,**kwargs)\n",
    "    return _check_stations(location_str, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a800000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f76741a",
   "metadata": {},
   "source": [
    "### Adding Customizable Window Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f01aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_selections = {\n",
    "    \"variable\": variable,\n",
    "    \"resolution\": \"3 km\",\n",
    "    \"q\": qtile,\n",
    "    \"warming_level\": warming_levels,\n",
    "    \"units\": units,\n",
    "    \"no_delta\": no_delta,\n",
    "    # warming level window\n",
    "    \"warming_level_window\": valid_window,\n",
    "    # Location options -- uncomment based on your desired location type\n",
    "    # \"stations\": station_name,  # uncomment for a weather station\n",
    "    \"latitude\": (\n",
    "        latitude - 0.02,\n",
    "        latitude + 0.02,\n",
    "    ),  # uncomment for a using a custom coordinate location\n",
    "    \"longitude\": (\n",
    "        longitude - 0.02,\n",
    "        longitude + 0.02,\n",
    "    ),  # uncomment for a custom coordinate location\n",
    "    # \"cached_area\": area_name, # uncomment for a cached area\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1c24681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Retrieving climate data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cbf32946cf4e25bb9db9437b23837b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data retrieval:   0%|          | 0/1 [00:00<?, ?dataset/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "No data found in bounds. Data variable: t2\n",
      "Skipping spatial subsetting.\n",
      "âš™ï¸  Computing climate profiles...\n",
      "      ðŸ“Š Processing 87,600 hours (10 years) of data\n",
      "      ðŸŽ¯ Computing 50th percentile for each hour of year\n",
      "      âš™ï¸ Computing quantiles for 1 warming level(s) and 8 simulation(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d633dd7ff68646048aed3f3a23dcc554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "      Computing profiles:   0%|          | 0/8 [00:00<?, ?combo/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate the climate profile\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m profile = \u001b[43mget_climate_profile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprofile_selections\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/climakitae/climakitae/explore/standard_year_profile.py:648\u001b[39m, in \u001b[36mget_climate_profile\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    645\u001b[39m \u001b[38;5;66;03m# Compute profiles for both datasets\u001b[39;00m\n\u001b[32m    646\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâš™ï¸  Computing climate profiles...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m future_profile = \u001b[43mcompute_profile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture_profile_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays_in_year\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdays_in_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m no_delta:\n\u001b[32m    652\u001b[39m     historic_profile = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/climakitae/climakitae/explore/standard_year_profile.py:1237\u001b[39m, in \u001b[36mcompute_profile\u001b[39m\u001b[34m(data, days_in_year, q)\u001b[39m\n\u001b[32m   1232\u001b[39m \u001b[38;5;66;03m# Group by hour_of_year and find the actual data value closest to the quantile\u001b[39;00m\n\u001b[32m   1233\u001b[39m \u001b[38;5;66;03m# This gives us the actual data point closest to the q-th quantile for each of the 8760 hours\u001b[39;00m\n\u001b[32m   1234\u001b[39m \u001b[38;5;66;03m# Load data to avoid dask chunking issues with quantile\u001b[39;00m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(subset_data.data, \u001b[33m\"\u001b[39m\u001b[33mchunks\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1236\u001b[39m     \u001b[38;5;66;03m# If it's a dask array, load it into memory\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m     subset_data = \u001b[43msubset_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_closest_to_quantile\u001b[39m(dat: xr.DataArray) -> xr.DataArray:\n\u001b[32m   1240\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the actual data value closest to the specified quantile.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/xarray/core/dataarray.py:1206\u001b[39m, in \u001b[36mDataArray.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1181\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[32m   1182\u001b[39m \u001b[33;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[32m   1183\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1203\u001b[39m \u001b[33;03mdask.compute\u001b[39;00m\n\u001b[32m   1204\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1205\u001b[39m new = \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/xarray/core/dataarray.py:1174\u001b[39m, in \u001b[36mDataArray.load\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs) -> Self:\n\u001b[32m   1155\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[32m   1156\u001b[39m \u001b[33;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[32m   1157\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1172\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m   1173\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m     ds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1175\u001b[39m     new = \u001b[38;5;28mself\u001b[39m._from_temp_dataset(ds)\n\u001b[32m   1176\u001b[39m     \u001b[38;5;28mself\u001b[39m._variable = new._variable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/xarray/core/dataset.py:900\u001b[39m, in \u001b[36mDataset.load\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    897\u001b[39m chunkmanager = get_chunked_array_type(*lazy_data.values())\n\u001b[32m    899\u001b[39m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np.ndarray[Any, Any], ...] = \u001b[43mchunkmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mlazy_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data, strict=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    905\u001b[39m     \u001b[38;5;28mself\u001b[39m.variables[k].data = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/xarray/namedarray/daskmanager.py:85\u001b[39m, in \u001b[36mDaskManager.compute\u001b[39m\u001b[34m(self, *data, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m, *data: Any, **kwargs: Any\n\u001b[32m     82\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[np.ndarray[Any, _DType_co], ...]:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdask\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/dask/base.py:660\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    657\u001b[39m     postcomputes.append(x.__dask_postcompute__())\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, *a) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/climakitae/lib/python3.12/queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/climakitae/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Generate the climate profile\n",
    "profile = get_climate_profile(**profile_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53d6e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_clean_standardyr_filename(\n",
    "    var_id: str,\n",
    "    q: float,\n",
    "    location: str,\n",
    "    gwl: float,\n",
    "    warming_level_window: int | None,\n",
    "    no_delta: bool,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Standardizes filename export for standard year files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    var_id : str\n",
    "        Name of variable used in profile\n",
    "    q : float\n",
    "        Percentile used in profile\n",
    "    location: str\n",
    "        String describing profile location\n",
    "    gwl : float\n",
    "        Single gwl for csv file name\n",
    "    warming_level_window: int\n",
    "        Years around Global Warming Level (+/-) (e.g. 15 means a 30yr window)\n",
    "\n",
    "    no_delta : bool\n",
    "        no_delta value used to generate profile\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A cleaned up file name\n",
    "    \"\"\"\n",
    "\n",
    "    # clean arguments for filenaming\n",
    "    clean_loc_name = location.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    clean_q_name = f\"{q:.2f}\".split(\".\")[1].lower()\n",
    "    clean_var_name = var_id.lower()\n",
    "    clean_gwl_name = match_str_to_wl(gwl).lower().replace(\".\", \"pt\")\n",
    "    if no_delta:\n",
    "        delta_str = \"\"\n",
    "    else:\n",
    "        delta_str = \"_delta_from_historical\"\n",
    "\n",
    "    if warming_level_window is None:\n",
    "        window_str = \"\"\n",
    "    else:\n",
    "        window_str = f\"_{warming_level_window}yr_window\"\n",
    "        print(window_str)\n",
    "\n",
    "    filename = f\"stdyr_{clean_var_name}_{clean_q_name}ptile_{clean_loc_name}_{clean_gwl_name}{delta_str}{window_str}.csv\"\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65d6daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_profile_to_csv(profile, **kwargs):\n",
    "    \"\"\"\n",
    "    Export profile to csv file with a descriptive file name.\n",
    "\n",
    "    Each warming level is saved in a separate file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    profile: pd.DataFrame\n",
    "        Standard year profile with MultiIndex columns\n",
    "\n",
    "    **kwargs : dict\n",
    "        Keyword arguments for data selection. Allowed keys:\n",
    "            variable : str\n",
    "                Name of variable used in profile\n",
    "            q : float\n",
    "                Percentile used in profile\n",
    "            global_warming_levels : list[float]\n",
    "                List of global warming levels in profile\n",
    "            warming_level_winow: int in range (5,25), optional\n",
    "                Years around Global Warming Level (+/-) (e.g. 15 means a 30yr window)\n",
    "            latitude : tuple(float | int), optional\n",
    "                Latitude coordinate range from profile location\n",
    "            longitude : tuple(float | int), optional\n",
    "                Longitude coordinate range from profile location\n",
    "            station_name : list[str], optional\n",
    "                Name of HadISD station(s) or custom location used in profile\n",
    "            cached_area : str, optional\n",
    "                Name of cached area used in profile\n",
    "            no_delta : bool, default False, optional\n",
    "                True if no_delta=True when generating profile\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    The function prioritizes location parameters in the following order:\n",
    "    1. cached_area\n",
    "    2. latitude/longitude\n",
    "    3. stations\n",
    "    Each parameter will override the lower-priority ones if provided. So if cached_area\n",
    "    is given, lat/lon and stations are ignored. If lat/lon are given, stations are\n",
    "    ignored. If stations are given, they are used only if neither cached_area nor lat/lon\n",
    "    are provided. With the exception of the case in which a single custom station name is\n",
    "    given. That name will be included in the filename only if lat/lon are given, and no\n",
    "    cached area.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get required parameter values\n",
    "    variable = kwargs.get(\"variable\")\n",
    "    q = kwargs.get(\"q\")\n",
    "    global_warming_levels = kwargs.get(\"warming_level\")\n",
    "\n",
    "    # Handle no_delta wand warming_level_window inputs\n",
    "    no_delta = kwargs.get(\"no_delta\", False)\n",
    "    warming_level_window = kwargs.get(\"warming_level_window\", None)\n",
    "\n",
    "    # Get variable id string to use in file name\n",
    "    variable_descriptions = read_csv_file(VARIABLE_DESCRIPTIONS_CSV_PATH)\n",
    "    var_id = variable_descriptions[\n",
    "        (variable_descriptions[\"display_name\"] == variable)\n",
    "        & (variable_descriptions[\"timescale\"] == \"hourly\")\n",
    "    ][\"variable_id\"].item()\n",
    "\n",
    "    # Get location string based on combination of location variables\n",
    "    func_list = [_check_cached_area, _check_lat_lon, _check_stations]\n",
    "    location_str = \"\"\n",
    "    for func in func_list:\n",
    "        location_str = func(location_str, **kwargs)\n",
    "\n",
    "    # Check profile MultiIndex to pull out data by Global Warming Level\n",
    "    match profile.keys().nlevels:\n",
    "        case 2:  # Single WL\n",
    "            gwl = global_warming_levels[0]\n",
    "            filename = _get_clean_standardyr_filename(\n",
    "                var_id, q, location_str, gwl, warming_level_window, no_delta\n",
    "            )\n",
    "            #profile.to_csv(filename)\n",
    "        case 3:  # Multiple WL (WL included in MultiIndex)\n",
    "            for gwl in global_warming_levels:  # Single file per WL\n",
    "                filename = _get_clean_standardyr_filename(\n",
    "                    var_id, q, location_str, gwl, warming_level_window, no_delta\n",
    "                )\n",
    "                #profile.xs(f\"WL_{gwl}\", level=\"Warming_Level\", axis=1).to_csv(filename)\n",
    "        case _:\n",
    "            raise ValueError(\n",
    "                f\"Profile MultiIndex should have two or three levels. Found {profile.keys().nlevels} levels.\"\n",
    "            )\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9add1f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_5yr_window\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'stdyr_t2_50ptile_sacramento_executive_airport_ksac_near-future_5yr_window.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the function uses the previously defined profile selections to generate the output file name\n",
    "export_profile_to_csv(profile, **profile_selections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climakitae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
