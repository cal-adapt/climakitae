import pytest
import xarray as xr
import pandas as pd
import numpy as np
import os
from climakitae.util.utils import (
    read_csv_file,
    get_closest_gridcell,
    add_dummy_time_to_wl,
)
from climakitae.core.paths import stations_csv_path
from climakitae.core.data_export import export
from climakitae.explore.threshold_tools import get_block_maxima, get_return_value
from climakitae.explore.vulnerability import (
    _export_no_e,
    _clean_wl_data,
    _filter_ba_models,
    _metric_agg,
    CavaParams,
    cava_data,
)


# @pytest.fixture
# def mock_input_locations():
#     """Fixture for creating a mock input locations DataFrame."""
#     return read_csv_file(stations_csv_path, index_col=0)[
#         ["station", "LAT_Y", "LON_X"]
#     ].rename(columns={"LAT_Y": "lat", "LON_X": "lon"})


##### DONE #####


# Test `export_no_e` on a series of potential exports.
def test_export_no_e(test_data_2022_monthly_45km):

    # Export dataset
    export_path = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), "random_file.nc"
    )
    _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")

    # Assert path exists
    assert os.path.exists(export_path), "The file should be created."

    # Try exporting it again
    _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")

    # Check that the file still exists and has not been modified
    assert os.path.exists(export_path), "The file should still exist."

    # Delete exported file
    os.remove(export_path)
    assert not os.path.exists(export_path), "The file should have been deleted."


def test_clean_wl_data(test_dataset_WL_Alamedacounty_45km_hourly):
    """Test on `_clean_wl_data` with separate_files=True"""
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly
    num_sims = len(orig_ds["all_sims"])

    # Assert that the simulation names are in their original form
    assert "all_sims" in orig_ds.dims, "Simulation dimension should be `all_sims`."
    assert (
        "WRF_CESM2_r11i1p1f1_Historical + SSP 3-7.0 -- Business as Usual"
        in orig_ds.all_sims
    ), "The format of all simulation names should include additional SSP text."

    # Assert that the simulation dimension gets changed correctly and test across both potential inputs for `separate_files`.
    # Re-assigining orig_ds to the original dataset because it gets mutated during each iteration of `_clean_wl_data`
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly.copy()
    ds = _clean_wl_data(orig_ds, "Dynamical", True)
    assert (
        "all_sims" not in ds.dims and "simulation" in ds.dims
    ), "Simulation dimension should be renamed."
    assert (
        len(ds["simulation"]) == num_sims
    ), "Number of simulations should not be changed."

    # Make sure descriptions for SSPs are removed
    def substring_exists(substring, lst):
        return any(substring in string for string in lst)

    assert not substring_exists("Business as Usual", ds["simulation"])
    assert (
        "WRF_CESM2_r11i1p1f1_Historical + SSP 3-7.0" in ds.simulation
    ), "The format of the simulation name should no longer include additional SSP text."


def test_filter_ba_models(test_dataset_WL_Alamedacounty_45km_hourly):

    # Rename `all_sims` to `simulation`
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly.copy()
    orig_ds = orig_ds.rename({"all_sims": "simulation"})

    # Assert that simulations are not filtered on other param inputs
    orig_ds_len = len(orig_ds.simulation)
    ds = _filter_ba_models(orig_ds, "Statistical", True, "Historical Climate")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."
    ds = _filter_ba_models(orig_ds, "Dynamical", False, "Historical Climate")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."
    ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Reconstruction")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."

    # Assert that simulations are actually filtered out
    ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Climate")
    wrf_bc_sims_45km = (
        "WRF_EC-Earth3_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual"
    )
    assert (
        wrf_bc_sims_45km in ds.simulation.values and len(ds.simulation.values) == 1
    ), "BC-WRF EC-Earth3 simulation should be in the post-filtered data AND the only simulation left for 45km WRF data."


def test_metric_agg():
    return


def cava_data():
    return


##### NOT DONE #####


def test_metric_agg_max_heat_index_threshold():
    # Create a sample DataArray
    data = np.random.random((365, 3)) * 40  # Random temperatures between 0 and 40
    da = xr.DataArray(
        data,
        dims=["time", "simulation"],
        coords={
            "time": pd.date_range("2000-01-01", periods=365),
            "simulation": ["sim1", "sim2", "sim3"],
        },
    )

    # Test the function
    result = _metric_agg(
        da,
        approach="time",
        metric="max",
        heat_idx_threshold=35,
        one_in_x=None,
        percentile=None,
        name_of_calc="max_temp_above_threshold",
        distr="gev",
    )

    # Assert that the result is correct (average days exceeding the threshold across years)
    assert result.mean().values > 0
    assert "max_temp_above_threshold" in result.name


# def test_clean_wl_data(test_dataset_WL_Alamedacounty_45km_hourly):
#     """Test on `_clean_wl_data` with separate_files=False"""
#     return


# Test cases

# downscaling method (2), approach (2), WL (4), ssp (3), historical (2), wrf_bias_adjust (2), variable (3), metric_calc (4), export_method (3), batch_mode (2)

# At least 10 ^^


# Tests for _export_no_e function
# def test_export_no_e(monkeypatch):
#     """Test _export_no_e function with a mock export."""

#     def mock_export(*args, **kwargs):
#         raise Exception("Mock exception for file exists")

#     monkeypatch.setattr(export, "export", mock_export)

#     # This test should ensure no exception is raised
#     try:
#         _export_no_e(None, "filename", "format")
#     except Exception as e:
#         pytest.fail(f"Export raised an exception: {e}")


# # Tests for _clean_wl_data function
# def test_clean_wl_data(mock_dataset):
#     """Test _clean_wl_data function."""
#     downscaling_method = "Dynamical"
#     cleaned_data = _clean_wl_data(mock_dataset, downscaling_method)
#     assert "x" in cleaned_data.dims, "X dimension not added correctly"
#     assert "y" in cleaned_data.dims, "Y dimension not added correctly"

# # Tests for _filter_ba_models function
# def test_filter_ba_models(mock_dataset):
#     """Test _filter_ba_models function."""
#     mock_dataset = mock_dataset.assign_coords(simulation=("time", ["WRF_EC-Earth3_r1i1p1f1"] * len(mock_dataset.time)))
#     downscaling_method = "Dynamical"
#     wrf_bias_adjust = True
#     historical_data = "Non-Historical"
#     filtered_data = _filter_ba_models(mock_dataset, downscaling_method, wrf_bias_adjust, historical_data)
#     assert "simulation" in filtered_data.coords, "Simulations not filtered correctly"

# # Tests for _get_closest_gridcell_and_separate_files function
# def test_get_closest_gridcell_and_separate_files(mock_dataset):
#     """Test _get_closest_gridcell_and_separate_files function."""
#     lat, lon = 1.5, 4.5
#     downscaling_method = "Dynamical"
#     separate_files = False
#     closest_cell = _get_closest_gridcell_and_separate_files(mock_dataset, lat, lon, downscaling_method, separate_files)
#     assert closest_cell is not None, "Closest grid cell not found correctly"

# # Tests for _metric_agg function
# def test_metric_agg(mock_dataset):
#     """Test _metric_agg function."""
#     approach = "warming_level"
#     metric = "max"
#     heat_idx_threshold = 0.5
#     one_in_x = 10
#     percentile = 90
#     name_of_calc = "Test Calc"
#     distr = "gev"
#     result = _metric_agg(mock_dataset, approach, metric, heat_idx_threshold, one_in_x, percentile, name_of_calc, distr)
#     assert result.name == name_of_calc, "Metric aggregation did not return expected result"

# # Tests for CavaParams class
# def test_cava_params_validation(mock_input_locations):
#     """Test CavaParams class for parameter validation."""
#     with pytest.raises(ValueError) as excinfo:
#         params = CavaParams(input_locations=mock_input_locations, time_start_year=2020, time_end_year=2010)
#     assert "Start year must come before" in str(excinfo.value), "Parameter validation did not catch error"

# # Tests for cava_data function
# def test_cava_data_function(mock_input_locations):
#     """Test cava_data function."""
#     try:
#         cava_data(
#             input_locations=mock_input_locations,
#             variable="Air Temperature at 2m"
#         )
#     except Exception as e:
#         pytest.fail(f"cava_data raised an exception: {e}")


# # Example of a mock dataset
# @pytest.fixture
# def mock_data():
#     # Create a simple xarray dataset with dimensions and variables
#     data = xr.Dataset(
#         {
#             "temperature": (("lat", "lon", "time"), np.random.rand(2, 2, 365)),
#         },
#         coords={
#             "lat": [34.05, 36.16],
#             "lon": [-118.24, -115.15],
#             "time": pd.date_range("2000-01-01", periods=365),
#         },
#     )
#     return data

# # Mock data retrieval function
# @patch('climakitae.core.data_load.load')
# def test_cava_data_with_mock_data(mock_load, mock_data):
#     # Configure the mock to return the mock dataset
#     mock_load.return_value = mock_data

#     # Input parameters
#     input_locations = pd.DataFrame({
#         'lat': [34.05],
#         'lon': [-118.24]
#     })

#     # Call the function with mocked data
#     result = cava_data(
#         input_locations=input_locations,
#         variable="Air Temperature at 2m",
#         approach="time",
#         downscaling_method="Dynamical",
#         time_start_year=2000,
#         time_end_year=2000,
#         historical_data="Historical Climate",
#         ssp_data=["SSP3-7.0"],
#         warming_level="1.5",
#         metric_calc="max",
#         heat_idx_threshold=None,
#         one_in_x=None,
#         percentile=90,
#         season="all",
#         wrf_bias_adjust=True,
#         export_method="both",
#         separate_files=True,
#         file_format="NetCDF",
#         batch_mode=False,
#         distr="gev",
#     )

#     # Assertions to validate the result
#     assert result is not None
#     assert isinstance(result, xr.Dataset)
#     # Add more assertions based on expected output

# def test_cava_params_validation():
#     # Test valid parameters
#     params = CavaParams(
#         input_locations=pd.DataFrame({
#             'lat': [34.05],
#             'lon': [-118.24]
#         }),
#         time_start_year=2000,
#         time_end_year=2010,
#         variable="Air Temperature at 2m",
#         metric_calc="max",
#         percentile=90,
#         approach="time",
#     )

#     assert params is not None

#     # Test invalid parameters
#     with pytest.raises(ValueError):
#         CavaParams(
#             input_locations=pd.DataFrame({
#                 'lat': [34.05],
#                 'lon': [-118.24]
#             }),
#             time_start_year=2010,
#             time_end_year=2000,  # Invalid because start > end
#             variable="Air Temperature at 2m",
#             metric_calc="max",
#             percentile=90,
#             approach="time",
#         )

# # Add more tests for other edge cases and functionalities
