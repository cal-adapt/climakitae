import pytest
import xarray as xr
import pandas as pd
import numpy as np
import os
from climakitae.util.utils import (
    read_csv_file,
    get_closest_gridcell,
    add_dummy_time_to_wl,
)
from climakitae.core.paths import stations_csv_path
from climakitae.core.data_export import export
from climakitae.explore.threshold_tools import get_block_maxima, get_return_value
from climakitae.explore.vulnerability import (
    _export_no_e,
    _clean_wl_data,
    _filter_ba_models,
    _metric_agg,
    CavaParams,
    cava_data,
)
from unittest.mock import MagicMock, patch


# Test `export_no_e` on a series of potential exports.
def test_export_no_e(test_data_2022_monthly_45km):
    """
    Test `_export_no_e` function to ensure it correctly handles exporting data to a file.

    The test verifies that:
    1. The function creates a file when it doesn't exist.
    2. The function does not modify an existing file when called again.
    3. The file is deleted correctly after the test.

    Parameters:
    test_data_2022_monthly_45km (xarray.Dataset): Test dataset used for export.
    """
    # Export dataset
    export_path = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), "random_file.nc"
    )
    _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")

    # Assert path exists
    assert os.path.exists(export_path), "The file should be created."

    # Try exporting it again
    _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")

    # Check that the file still exists and has not been modified
    assert os.path.exists(export_path), "The file should still exist."

    # Delete exported file
    os.remove(export_path)
    assert not os.path.exists(export_path), "The file should have been deleted."


def test_clean_wl_data(test_dataset_WL_Alamedacounty_45km_hourly):
    """
    Test `_clean_wl_data` function to ensure it correctly cleans and renames the simulation dimension.

    The test asserts that:
    1. The `all_sims` dimension is renamed to `simulation`.
    2. Descriptions for SSPs are removed when `separate_files` is True.
    3. The original number of simulations is preserved.

    Parameters:
    test_dataset_WL_Alamedacounty_45km_hourly (xarray.Dataset): Test dataset used for cleaning.
    """
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly
    num_sims = len(orig_ds["all_sims"])

    # Assert that the simulation names are in their original form
    assert "all_sims" in orig_ds.dims, "Simulation dimension should be `all_sims`."
    assert (
        "WRF_CESM2_r11i1p1f1_Historical + SSP 3-7.0 -- Business as Usual"
        in orig_ds.all_sims
    ), "The format of all simulation names should include additional SSP text."

    # Assert that the simulation dimension gets changed correctly and test across both potential inputs for `separate_files`.
    # Re-assigining orig_ds to the original dataset because it gets mutated during each iteration of `_clean_wl_data`
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly.copy()
    ds = _clean_wl_data(orig_ds, "Dynamical", True)
    assert (
        "all_sims" not in ds.dims and "simulation" in ds.dims
    ), "Simulation dimension should be renamed."
    assert (
        len(ds["simulation"]) == num_sims
    ), "Number of simulations should not be changed."

    # Make sure descriptions for SSPs are removed
    def substring_exists(substring, lst):
        return any(substring in string for string in lst)

    assert not substring_exists("Business as Usual", ds["simulation"])
    assert (
        "WRF_CESM2_r11i1p1f1_Historical + SSP 3-7.0" in ds.simulation
    ), "The format of the simulation name should no longer include additional SSP text."


def test_filter_ba_models(test_dataset_WL_Alamedacounty_45km_hourly):
    """
    Test `_filter_ba_models` function to ensure it correctly filters simulations based on input parameters.

    The test asserts that:
    1. Simulations are not filtered out under non-filtering conditions.
    2. The correct simulation is filtered out under filtering conditions.

    Parameters:
    test_dataset_WL_Alamedacounty_45km_hourly (xarray.Dataset): Test dataset used for filtering.
    """
    # Rename `all_sims` to `simulation`
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly.copy()
    orig_ds = orig_ds.rename({"all_sims": "simulation"})

    # Assert that simulations are not filtered on other param inputs
    orig_ds_len = len(orig_ds.simulation)
    ds = _filter_ba_models(orig_ds, "Statistical", True, "Historical Climate")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."
    ds = _filter_ba_models(orig_ds, "Dynamical", False, "Historical Climate")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."
    ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Reconstruction")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."

    # Assert that simulations are actually filtered out
    ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Climate")
    wrf_bc_sims_45km = [
        ("WRF_EC-Earth3_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual"),
        ("WRF_EC-Earth3-Veg_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual"),
    ]
    assert (
        wrf_bc_sims_45km[0] in ds.simulation.values
        and wrf_bc_sims_45km[1] in ds.simulation.values
        and len(ds.simulation.values) == 2
    ), "BC-WRF EC-Earth3 anbd EC-Earth3-Veg simulations should be the only ones in the post-filtered data AND the only simulations left for 45km WRF data."


def test_metric_agg(test_dataarray_time_2030_2035_wrf_3km_hourly_temp):
    """
    Test `_metric_agg` function to ensure it correctly aggregates metrics over time or space.

    The test verifies that:
    1. The output type is an xarray DataArray.
    2. The output shape and dimensions are as expected.
    3. Values are within expected ranges.
    4. The new name of the DataArray is correctly assigned.

    Parameters:
    test_dataarray_time_2030_2035_wrf_3km_hourly_temp (xarray.Dataset): Test dataset used for metric aggregation.
    """
    # Grab dataset and number of simulations
    ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
    num_sims = len(ds.simulation)
    new_name = "test_name"

    # Heat Index test
    calc_val = _metric_agg(
        ds,
        "Air Temperature at 2m",
        np.arange(1, 13),
        "time",
        "max",
        new_name,
        91,
        None,
        None,
        (1, "day"),
        "gev",
    )

    assert (
        type(calc_val) == xr.core.dataarray.DataArray
    ), "The output type of `metric_agg` should be an xarray DataArray."

    print(calc_val)
    assert calc_val.shape == (
        1,  # scenario
        num_sims,  # simulation
        1,  # y
        1,  # x
    ), "This is not an expected output shape of `metric_agg`."
    assert (
        "simulation" in calc_val.dims
    ), "Simulation should remain in the expected output of `metric_agg`."
    assert (
        "time" not in calc_val.dims
    ), "Time should not be in the dimensions after `metric_agg` is calculated."
    assert np.all(
        (calc_val >= 0) & (calc_val < 366)
    ), "All values should be between 0 and 366 (no above heat index days to only above heat index days)"
    assert (
        calc_val.name == new_name
    ), "New name of DataArray should be carried on from argument."

    # Percentile test
    calc_val = _metric_agg(
        ds,
        "Air Temperature at 2m",
        np.arange(1, 13),
        "time",
        "max",
        new_name,
        None,
        95,
        None,
        (1, "day"),
        "gev",
    )

    assert (
        type(calc_val) == xr.core.dataarray.DataArray
    ), "The output type of `metric_agg` should be an xarray DataArray."
    assert calc_val.shape == (
        1,  # scenario
        num_sims,  # simulation
        1,  # y
        1,  # x
    ), "This is not an expected output shape of `metric_agg`."
    assert (
        "simulation" in calc_val.dims
    ), "Simulation should remain in the expected output of `metric_agg`."
    assert (
        "time" not in calc_val.dims
    ), "Time should not be in the dimensions after `metric_agg` is calculated."
    assert (
        "lat" in calc_val.coords and "lon" in calc_val.coords
    ), "Lat and lon dimensions should exist after percentile `metric_calc`."
    assert np.all(
        calc_val < ds.max()
    ), "95th yearly percentiles should all be below the max of the entire DataArray."
    assert (
        calc_val.name == new_name
    ), "New name of DataArray should be carried on from argument."

    # One-in-X test
    calc_val = _metric_agg(
        ds,
        "Air Temperature at 2m",
        np.arange(1, 13),
        "time",
        "max",
        new_name,
        None,
        None,
        10,
        (1, "day"),
        "gev",
    )

    assert (
        type(calc_val) == xr.core.dataarray.DataArray
    ), "The output type of `metric_agg` should be an xarray DataArray."
    assert calc_val.shape == (
        num_sims,
    ), "This is not an expected output shape of `metric_agg`."
    assert (
        "simulation" in calc_val.dims
    ), "The expected output dimension of `metric_agg` 1-in-X has `simulation`."
    assert (
        calc_val.name == new_name
    ), "New name of DataArray should be carried on from argument."


inputs = [
    ## WRF Time
    (
        "Air Temperature at 2m",
        "Dynamical",
        "Time",
        "Historical Climate",
        ["SSP3-7.0"],
        False,
        1.5,
        "min",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_wrf_3km_hourly_temp",
    ),
    ### LOCA Time
    (
        "Air Temperature at 2m",
        "Statistical",
        "Time",
        "Historical Climate",
        ["SSP3-7.0"],
        False,
        1.5,
        "max",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_loca_3km_daily_temp",
    ),
    ### WRF WL
    (
        "Air Temperature at 2m",
        "Dynamical",
        "Warming Level",
        "Historical Climate",
        ["SSP3-7.0"],
        False,
        2.0,
        "min",
        "all",
        "calculate",
        False,
        "test_dataarray_wl_20_all_season_wrf_3km_hourly_temp",
    ),
    ### LOCA WL all seasons
    (
        "Air Temperature at 2m",
        "Statistical",
        "Warming Level",
        "Historical Climate",
        ["SSP3-7.0"],
        False,
        2.0,
        "max",
        "all",
        "raw",
        False,
        "test_dataarray_wl_20_all_season_loca_3km_daily_temp",
    ),
    # LOCA WL summer
    (
        "Air Temperature at 2m",
        "Statistical",
        "Warming Level",
        "Historical Climate",
        ["SSP3-7.0"],
        False,
        2.0,
        "max",
        "summer",
        "raw",
        False,
        "test_dataarray_wl_20_summer_season_loca_3km_daily_temp",
    ),
    # ## NOAA Heat Index test
    (
        "NOAA Heat Index",
        "Dynamical",
        "Time",
        "Historical Climate",
        ["SSP3-7.0"],
        True,
        1.5,
        "min",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_wrf_3km_hourly_heat_index",
    ),
    ### Historical Reconstruction, no batch
    (
        "Air Temperature at 2m",
        "Dynamical",
        "Time",
        "Historical Reconstruction",
        ["SSP3-7.0"],
        False,
        1.5,
        "max",
        "all",
        "both",
        False,
        "test_dataarray_time_2010_2015_histrecon_wrf_3km_hourly_temp_single_cell",
    ),
    ## Historical Reconstruction, batch
    (
        "Air Temperature at 2m",
        "Dynamical",
        "Time",
        "Historical Reconstruction",
        ["SSP3-7.0"],
        False,
        1.5,
        "max",
        "all",
        "both",
        True,
        "test_dataarray_time_2010_2015_histrecon_wrf_3km_hourly_temp_gridded_area",
    ),
    ### Precipitation test
    (
        "Precipitation (total)",
        "Dynamical",
        "Time",
        "Historical Climate",
        ["SSP3-7.0"],
        False,
        2.0,
        "max",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_wrf_3km_hourly_prec",
    ),
]


@pytest.mark.parametrize(
    "variable, downscaling_method, approach, historical_data, ssp_data, wrf_bias_adjust, warming_level, metric_calc, season, export_method, batch_mode, test_dataset_fixture",
    inputs,
)
def test_cava_data_params(
    request,
    variable,
    downscaling_method,
    approach,
    historical_data,
    ssp_data,
    wrf_bias_adjust,
    warming_level,
    metric_calc,
    season,
    export_method,
    batch_mode,
    test_dataset_fixture,
):

    test_dataset = request.getfixturevalue(test_dataset_fixture)

    with (
        patch(
            "climakitae.core.data_interface.DataParameters.retrieve",
            return_value=test_dataset,
        ),
        patch("climakitae.explore.vulnerability._export_no_e", return_value=None),
    ):
        input_locations = pd.DataFrame(
            {"lat": [35.43424, 35.4], "lon": [-119.05524, -119.02176]}
        )

        batch = 2 if batch_mode else 1

        if historical_data == "Historical Climate":
            start_year, end_year = 2030, 2035
        elif historical_data == "Historical Reconstruction":
            start_year, end_year = 2010, 2015

        result = cava_data(
            ## Set-up
            input_locations.iloc[:batch],  # select a single location
            time_start_year=start_year,
            time_end_year=end_year,
            warming_level=warming_level,
            downscaling_method=downscaling_method,  # WRF data
            approach=approach,
            historical_data=historical_data,
            ssp_data=ssp_data,
            wrf_bias_adjust=False,  # return all WRF models
            batch_mode=batch_mode,
            ## Likely seaonal event specific arguments
            variable=variable,
            metric_calc=metric_calc,  # daily high temperature
            percentile=75,  # likeliness percentile
            season=season,  # season
            units="degF",  # change units
            ## Export
            export_method="both",  # export only calculated metric data
            file_format="NetCDF",
        )

        def check_raw_output(result):
            days_by_season = {
                "winter": 90,
                "summer": 92,
                "all": 365,
            }
            assert "raw_data" in result
            raw_res = result["raw_data"]
            if downscaling_method == "Dynamical":
                if approach == "Time":
                    if historical_data == "Historical Reconstruction":
                        assert raw_res.shape == (
                            batch,
                            (end_year - start_year + 1) * days_by_season[season] * 24,
                        )  # Finding the total number of hours after filtering for specific seasons
                    elif wrf_bias_adjust == True:
                        num_sims = 5 * batch
                        assert raw_res.shape == (
                            1,
                            num_sims,
                            (end_year - start_year + 1) * days_by_season[season] * 24,
                        )  # Finding the total number of hours after filtering for specific seasons
                    elif wrf_bias_adjust == False:
                        num_sims = 8 * batch
                        assert raw_res.shape == (
                            1,
                            num_sims,
                            (end_year - start_year + 1) * days_by_season[season] * 24,
                        )  # Finding the total number of hours after filtering for specific seasons
                elif approach == "Warming Level":
                    assert raw_res.shape == (
                        1,
                        8 * batch,
                        30
                        * days_by_season[season]
                        * 24,  # Pre-determined as 30-year WL slices; finding the total number of hours
                    )
                assert raw_res.name == variable
            elif downscaling_method == "Statistical":
                if approach == "Time":
                    assert raw_res.shape == (
                        1,
                        62 * batch,
                        (end_year - start_year + 1) * days_by_season[season],
                    )  # Finding the total number of hours after filtering for specific seasons
                elif approach == "Warming Level":
                    assert raw_res.shape == (
                        1,
                        30
                        * days_by_season[
                            season
                        ],  # Pre-determined as 30-year WL slices; finding the total number of days
                        129 * batch,
                    )
                # Make sure that raw dataset pulls the correct, re-defined LOCA variable for `Air Temperature at 2m`
                if metric_calc == "max" and variable == "Air Temperature at 2m":
                    assert raw_res.name == "Maximum air temperature at 2m"
                elif metric_calc == "min" and variable == "Air Temperature at 2m":
                    assert raw_res.name == "Minimum air temperature at 2m"

        def check_calculate_output(result):
            assert "calc_data" in result
            calc_res = result["calc_data"]
            # Check for shape and coords depending on downscaling method
            if downscaling_method == "Dynamical":
                if approach == "Time":
                    if ssp_data == ["SSP 3-7.0"]:
                        assert (
                            calc_res.scenario.item()
                            == "Historical + SSP 3-7.0 -- Business as Usual"
                        )
                if historical_data == "Historical Reconstruction":
                    assert calc_res.shape == (1 * batch,)
                elif not wrf_bias_adjust:
                    assert calc_res.shape == (1, 8 * batch)
                elif wrf_bias_adjust:
                    assert calc_res.shape == (1, 5 * batch)
                assert calc_res.frequency == "hourly"
                if not batch_mode:
                    assert np.isclose(calc_res.lat.item(), 35.43, atol=0.02)
                    assert np.isclose(calc_res.lon.item(), -119.04, atol=0.02)
                    assert np.isclose(calc_res.x.item(), -4089113.66, atol=5000)
                    assert np.isclose(calc_res.y.item(), 1012911.12, atol=5000)
                else:
                    assert np.all(
                        np.isclose(calc_res.lat, [35.445045, 35.400005], atol=0.1)
                    )
                    assert np.all(
                        np.isclose(calc_res.lon, [-119.06061, -119.02176], atol=0.1)
                    )
                    assert np.isclose(calc_res.x, -4089113.66, atol=5000)
                    assert np.all(
                        np.isclose(
                            calc_res.y, [1015911.73069854, 1009911.73069854], atol=5000
                        )
                    )

            elif downscaling_method == "Statistical":
                if approach == "Time":
                    if ssp_data == ["SSP 3-7.0"]:
                        assert (
                            calc_res.scenario.item()
                            == "Historical + SSP 3-7.0 -- Business as Usual"
                        )
                    assert calc_res.shape == (1, 62)
                elif approach == "Warming Level":
                    assert calc_res.shape == (1, 129)
                assert calc_res.frequency == "daily"
                assert np.isclose(calc_res.lat.item(), 35.42, atol=0.01)
                assert np.isclose(calc_res.lon.item(), -119.05, atol=0.01)

            if ssp_data == ["SSP 3-7.0"]:
                assert (
                    calc_res.scenario.item()
                    == "Historical + SSP 3-7.0 -- Business as Usual"
                )

            assert calc_res.resolution == "3 km"
            if (
                calc_res.variable_id == "t2"
                or calc_res.variable_id == "tasmax"
                or calc_res.variable_id == "noaa_heat_index_derived"
            ):
                assert calc_res.units == "degF"
            elif calc_res.variable_id == "prec":
                assert calc_res.units == "inches"
            # assert calc_res.name == '75th percentile of Daily Min of Air Temperature at 2m for summer seasons from 2030_to_2035'
            assert calc_res.percentile.item() == 75

        # Check for appropriate data structures
        assert isinstance(result, dict)

        if export_method == "raw":
            check_raw_output(result)

        elif export_method == "calculate":
            check_calculate_output(result)

        elif export_method == "both":
            check_raw_output(result)
            check_calculate_output(result)
