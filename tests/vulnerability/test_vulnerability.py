import pytest
import xarray as xr
import pandas as pd
import numpy as np
import os
from climakitae.util.utils import (
    read_csv_file,
    get_closest_gridcell,
    add_dummy_time_to_wl,
)
from climakitae.core.paths import stations_csv_path
from climakitae.core.data_export import export
from climakitae.explore.threshold_tools import get_block_maxima, get_return_value
from climakitae.explore.vulnerability import (
    _export_no_e,
    _clean_wl_data,
    _filter_ba_models,
    _metric_agg,
    CavaParams,
    cava_data,
)

##### DONE #####


# Test `export_no_e` on a series of potential exports.
def test_export_no_e(test_data_2022_monthly_45km):
    """
    Test `_export_no_e` function to ensure it correctly handles exporting data to a file.

    The test verifies that:
    1. The function creates a file when it doesn't exist.
    2. The function does not modify an existing file when called again.
    3. The file is deleted correctly after the test.

    Parameters:
    test_data_2022_monthly_45km (xarray.Dataset): Test dataset used for export.
    """
    # Export dataset
    export_path = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), "random_file.nc"
    )
    _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")

    # Assert path exists
    assert os.path.exists(export_path), "The file should be created."

    # Try exporting it again
    _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")

    # Check that the file still exists and has not been modified
    assert os.path.exists(export_path), "The file should still exist."

    # Delete exported file
    os.remove(export_path)
    assert not os.path.exists(export_path), "The file should have been deleted."


def test_clean_wl_data(test_dataset_WL_Alamedacounty_45km_hourly):
    """
    Test `_clean_wl_data` function to ensure it correctly cleans and renames the simulation dimension.

    The test asserts that:
    1. The `all_sims` dimension is renamed to `simulation`.
    2. Descriptions for SSPs are removed when `separate_files` is True.
    3. The original number of simulations is preserved.

    Parameters:
    test_dataset_WL_Alamedacounty_45km_hourly (xarray.Dataset): Test dataset used for cleaning.
    """
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly
    num_sims = len(orig_ds["all_sims"])

    # Assert that the simulation names are in their original form
    assert "all_sims" in orig_ds.dims, "Simulation dimension should be `all_sims`."
    assert (
        "WRF_CESM2_r11i1p1f1_Historical + SSP 3-7.0 -- Business as Usual"
        in orig_ds.all_sims
    ), "The format of all simulation names should include additional SSP text."

    # Assert that the simulation dimension gets changed correctly and test across both potential inputs for `separate_files`.
    # Re-assigining orig_ds to the original dataset because it gets mutated during each iteration of `_clean_wl_data`
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly.copy()
    ds = _clean_wl_data(orig_ds, "Dynamical", True)
    assert (
        "all_sims" not in ds.dims and "simulation" in ds.dims
    ), "Simulation dimension should be renamed."
    assert (
        len(ds["simulation"]) == num_sims
    ), "Number of simulations should not be changed."

    # Make sure descriptions for SSPs are removed
    def substring_exists(substring, lst):
        return any(substring in string for string in lst)

    assert not substring_exists("Business as Usual", ds["simulation"])
    assert (
        "WRF_CESM2_r11i1p1f1_Historical + SSP 3-7.0" in ds.simulation
    ), "The format of the simulation name should no longer include additional SSP text."


def test_filter_ba_models(test_dataset_WL_Alamedacounty_45km_hourly):
    """
    Test `_filter_ba_models` function to ensure it correctly filters simulations based on input parameters.

    The test asserts that:
    1. Simulations are not filtered out under non-filtering conditions.
    2. The correct simulation is filtered out under filtering conditions.

    Parameters:
    test_dataset_WL_Alamedacounty_45km_hourly (xarray.Dataset): Test dataset used for filtering.
    """
    # Rename `all_sims` to `simulation`
    orig_ds = test_dataset_WL_Alamedacounty_45km_hourly.copy()
    orig_ds = orig_ds.rename({"all_sims": "simulation"})

    # Assert that simulations are not filtered on other param inputs
    orig_ds_len = len(orig_ds.simulation)
    ds = _filter_ba_models(orig_ds, "Statistical", True, "Historical Climate")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."
    ds = _filter_ba_models(orig_ds, "Dynamical", False, "Historical Climate")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."
    ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Reconstruction")
    assert len(ds.simulation) == orig_ds_len, "No simulations should be changed."

    # Assert that simulations are actually filtered out
    ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Climate")
    wrf_bc_sims_45km = (
        "WRF_EC-Earth3_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual"
    )
    assert (
        wrf_bc_sims_45km in ds.simulation.values and len(ds.simulation.values) == 1
    ), "BC-WRF EC-Earth3 simulation should be in the post-filtered data AND the only simulation left for 45km WRF data."


def test_metric_agg(test_dataset_time_single_cell_3km_hourly_2025_2030):
    """
    Test `_metric_agg` function to ensure it correctly aggregates metrics over time or space.

    The test verifies that:
    1. The output type is an xarray DataArray.
    2. The output shape and dimensions are as expected.
    3. Values are within expected ranges.
    4. The new name of the DataArray is correctly assigned.

    Parameters:
    test_dataset_time_single_cell_3km_hourly_2025_2030 (xarray.Dataset): Test dataset used for metric aggregation.
    """
    # Grab dataset and number of simulations
    ds = test_dataset_time_single_cell_3km_hourly_2025_2030.copy()
    num_sims = len(ds.simulation)
    new_name = "test_name"

    # Heat Index test
    calc_val = _metric_agg(ds, "time", "max", 91, None, None, new_name, None)
    assert (
        type(calc_val) == xr.core.dataarray.DataArray
    ), "The output type of `metric_agg` should be an xarray DataArray."
    assert calc_val.shape == (
        1,
        num_sims,
    ), "This is not an expected output shape of `metric_agg`."
    assert (
        "simulation" in calc_val.dims
    ), "Simulation should remain in the expected output of `metric_agg`."
    assert (
        "time" not in calc_val.dims
    ), "Time should not be in the dimensions after `metric_agg` is calculated."
    assert np.all(
        (calc_val >= 0) & (calc_val < 365)
    ), "All values should be between 0 and 365 (no above heat index days to only above heat index days)"
    assert (
        calc_val.name == new_name
    ), "New name of DataArray should be carried on from argument."

    # One-in-X test
    calc_val = _metric_agg(ds, "time", "max", None, 10, None, new_name, "gev")
    assert (
        type(calc_val) == xr.core.dataarray.DataArray
    ), "The output type of `metric_agg` should be an xarray DataArray."
    assert calc_val.shape == (
        num_sims,
    ), "This is not an expected output shape of `metric_agg`."
    assert (
        "simulation" in calc_val.dims and len(calc_val.dims) == 1
    ), "The expected output dimension of `metric_agg` 1-in-X is just `simulation`."
    assert (
        calc_val.name == new_name
    ), "New name of DataArray should be carried on from argument."

    # Percentile test
    calc_val = _metric_agg(ds, "time", "max", None, None, 95, new_name, None)
    assert (
        type(calc_val) == xr.core.dataarray.DataArray
    ), "The output type of `metric_agg` should be an xarray DataArray."
    assert calc_val.shape == (
        1,
        num_sims,
    ), "This is not an expected output shape of `metric_agg`."
    assert (
        "simulation" in calc_val.dims
    ), "Simulation should remain in the expected output of `metric_agg`."
    assert (
        "time" not in calc_val.dims
    ), "Time should not be in the dimensions after `metric_agg` is calculated."
    assert (
        "lat" in calc_val.coords and "lon" in calc_val.coords
    ), "Lat and lon dimensions should exist after percentile `metric_calc`."
    assert np.all(
        calc_val < ds.max()
    ), "95th yearly percentiles should all be below the max of the entire DataArray."
    assert (
        calc_val.name == new_name
    ), "New name of DataArray should be carried on from argument."


def cava_data():
    return


##### NOT DONE #####

# @pytest.fixture
# def mock_input_locations():
#     """Fixture for creating a mock input locations DataFrame."""
#     return read_csv_file(stations_csv_path, index_col=0)[
#         ["station", "LAT_Y", "LON_X"]
#     ].rename(columns={"LAT_Y": "lat", "LON_X": "lon"})


# def test_clean_wl_data(test_dataset_WL_Alamedacounty_45km_hourly):
#     """Test on `_clean_wl_data` with separate_files=False"""
#     return


# Test cases

# downscaling method (2), approach (2), WL (4), ssp (3), historical (2), wrf_bias_adjust (2), variable (3), metric_calc (4), export_method (3), batch_mode (2)

# At least 10 ^^


# Tests for _export_no_e function
# def test_export_no_e(monkeypatch):
#     """Test _export_no_e function with a mock export."""

#     def mock_export(*args, **kwargs):
#         raise Exception("Mock exception for file exists")

#     monkeypatch.setattr(export, "export", mock_export)

#     # This test should ensure no exception is raised
#     try:
#         _export_no_e(None, "filename", "format")
#     except Exception as e:
#         pytest.fail(f"Export raised an exception: {e}")


# # Tests for _clean_wl_data function
# def test_clean_wl_data(mock_dataset):
#     """Test _clean_wl_data function."""
#     downscaling_method = "Dynamical"
#     cleaned_data = _clean_wl_data(mock_dataset, downscaling_method)
#     assert "x" in cleaned_data.dims, "X dimension not added correctly"
#     assert "y" in cleaned_data.dims, "Y dimension not added correctly"

# # Tests for _filter_ba_models function
# def test_filter_ba_models(mock_dataset):
#     """Test _filter_ba_models function."""
#     mock_dataset = mock_dataset.assign_coords(simulation=("time", ["WRF_EC-Earth3_r1i1p1f1"] * len(mock_dataset.time)))
#     downscaling_method = "Dynamical"
#     wrf_bias_adjust = True
#     historical_data = "Non-Historical"
#     filtered_data = _filter_ba_models(mock_dataset, downscaling_method, wrf_bias_adjust, historical_data)
#     assert "simulation" in filtered_data.coords, "Simulations not filtered correctly"

# # Tests for _get_closest_gridcell_and_separate_files function
# def test_get_closest_gridcell_and_separate_files(mock_dataset):
#     """Test _get_closest_gridcell_and_separate_files function."""
#     lat, lon = 1.5, 4.5
#     downscaling_method = "Dynamical"
#     separate_files = False
#     closest_cell = _get_closest_gridcell_and_separate_files(mock_dataset, lat, lon, downscaling_method, separate_files)
#     assert closest_cell is not None, "Closest grid cell not found correctly"

# # Tests for _metric_agg function
# def test_metric_agg(mock_dataset):
#     """Test _metric_agg function."""
#     approach = "warming_level"
#     metric = "max"
#     heat_idx_threshold = 0.5
#     one_in_x = 10
#     percentile = 90
#     name_of_calc = "Test Calc"
#     distr = "gev"
#     result = _metric_agg(mock_dataset, approach, metric, heat_idx_threshold, one_in_x, percentile, name_of_calc, distr)
#     assert result.name == name_of_calc, "Metric aggregation did not return expected result"

# # Tests for CavaParams class
# def test_cava_params_validation(mock_input_locations):
#     """Test CavaParams class for parameter validation."""
#     with pytest.raises(ValueError) as excinfo:
#         params = CavaParams(input_locations=mock_input_locations, time_start_year=2020, time_end_year=2010)
#     assert "Start year must come before" in str(excinfo.value), "Parameter validation did not catch error"

# # Tests for cava_data function
# def test_cava_data_function(mock_input_locations):
#     """Test cava_data function."""
#     try:
#         cava_data(
#             input_locations=mock_input_locations,
#             variable="Air Temperature at 2m"
#         )
#     except Exception as e:
#         pytest.fail(f"cava_data raised an exception: {e}")


# # Example of a mock dataset
# @pytest.fixture
# def mock_data():
#     # Create a simple xarray dataset with dimensions and variables
#     data = xr.Dataset(
#         {
#             "temperature": (("lat", "lon", "time"), np.random.rand(2, 2, 365)),
#         },
#         coords={
#             "lat": [34.05, 36.16],
#             "lon": [-118.24, -115.15],
#             "time": pd.date_range("2000-01-01", periods=365),
#         },
#     )
#     return data

# # Mock data retrieval function
# @patch('climakitae.core.data_load.load')
# def test_cava_data_with_mock_data(mock_load, mock_data):
#     # Configure the mock to return the mock dataset
#     mock_load.return_value = mock_data

#     # Input parameters
#     input_locations = pd.DataFrame({
#         'lat': [34.05],
#         'lon': [-118.24]
#     })

#     # Call the function with mocked data
#     result = cava_data(
#         input_locations=input_locations,
#         variable="Air Temperature at 2m",
#         approach="time",
#         downscaling_method="Dynamical",
#         time_start_year=2000,
#         time_end_year=2000,
#         historical_data="Historical Climate",
#         ssp_data=["SSP3-7.0"],
#         warming_level="1.5",
#         metric_calc="max",
#         heat_idx_threshold=None,
#         one_in_x=None,
#         percentile=90,
#         season="all",
#         wrf_bias_adjust=True,
#         export_method="both",
#         separate_files=True,
#         file_format="NetCDF",
#         batch_mode=False,
#         distr="gev",
#     )

#     # Assertions to validate the result
#     assert result is not None
#     assert isinstance(result, xr.Dataset)
#     # Add more assertions based on expected output

# def test_cava_params_validation():
#     # Test valid parameters
#     params = CavaParams(
#         input_locations=pd.DataFrame({
#             'lat': [34.05],
#             'lon': [-118.24]
#         }),
#         time_start_year=2000,
#         time_end_year=2010,
#         variable="Air Temperature at 2m",
#         metric_calc="max",
#         percentile=90,
#         approach="time",
#     )

#     assert params is not None

#     # Test invalid parameters
#     with pytest.raises(ValueError):
#         CavaParams(
#             input_locations=pd.DataFrame({
#                 'lat': [34.05],
#                 'lon': [-118.24]
#             }),
#             time_start_year=2010,
#             time_end_year=2000,  # Invalid because start > end
#             variable="Air Temperature at 2m",
#             metric_calc="max",
#             percentile=90,
#             approach="time",
#         )

# # Add more tests for other edge cases and functionalities
