import os
from unittest.mock import patch

import numpy as np
import pandas as pd
import pytest
import xarray as xr

from climakitae.core.constants import UNSET
from climakitae.explore.vulnerability import (
    _export_no_e,
    _filter_ba_models,
    _metric_agg,
    cava_data,
)


class TestExportNoE:
    """Tests for the `_export_no_e` export function."""

    def test_creates_and_overwrites_file(self, test_data_2022_monthly_45km):
        """Test that _export_no_e creates a file and handles existing files gracefully."""
        export_path = os.path.join(
            os.path.dirname(os.path.abspath(__file__)), "random_file.nc"
        )
        _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")
        assert os.path.exists(export_path), "The file should be created."

        # Try exporting it again
        _export_no_e(test_data_2022_monthly_45km, export_path, "NetCDF")
        assert os.path.exists(export_path), "The file should still exist."

        # Cleanup
        os.remove(export_path)
        assert not os.path.exists(export_path), "The file should have been deleted."


class TestFilterBAModels:
    """Tests for the `_filter_ba_models` simulation filtering function."""

    def test_no_filtering_on_non_matching_params(
        self, test_dataarray_wl_20_all_season_wrf_3km_hourly_temp
    ):
        """Simulations should not be filtered under non-filtering conditions."""
        orig_ds = test_dataarray_wl_20_all_season_wrf_3km_hourly_temp.copy()
        orig_ds_len = len(orig_ds.simulation)

        ds = _filter_ba_models(orig_ds, "Statistical", True, "Historical Climate")
        assert len(ds.simulation) == orig_ds_len

        ds = _filter_ba_models(orig_ds, "Dynamical", False, "Historical Climate")
        assert len(ds.simulation) == orig_ds_len

        ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Reconstruction")
        assert len(ds.simulation) == orig_ds_len

    def test_filters_to_bias_adjusted_models(
        self, test_dataarray_wl_20_all_season_wrf_3km_hourly_temp
    ):
        """Filtering should retain only bias-adjusted WRF models."""
        orig_ds = test_dataarray_wl_20_all_season_wrf_3km_hourly_temp.copy()
        ds = _filter_ba_models(orig_ds, "Dynamical", True, "Historical Climate")

        wrf_bc_sims_45km = np.array(
            [
                "WRF_EC-Earth3_r1i1p1f1_historical+ssp370",
                "WRF_EC-Earth3-Veg_r1i1p1f1_historical+ssp370",
                "WRF_MIROC6_r1i1p1f1_historical+ssp370",
                "WRF_MPI-ESM1-2-HR_r3i1p1f1_historical+ssp370",
                "WRF_TaiESM1_r1i1p1f1_historical+ssp370",
            ]
        )
        assert np.array_equal(ds.simulation.values, wrf_bc_sims_45km)


class TestMetricAgg:
    """Tests for the `_metric_agg` metric aggregation function."""

    def test_heat_index_threshold(
        self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp
    ):
        """Heat index threshold should produce a DataArray with correct shape."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)
        new_name = "test_name"

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            new_name,
            91,
            None,
            np.array([None]),
            groupby=(1, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.DataArray)
        assert calc_val.shape == (1, num_sims, 1, 1)
        assert "simulation" in calc_val.dims
        assert "time" not in calc_val.dims
        assert np.all((calc_val >= 0) & (calc_val < 366))
        assert calc_val.name == new_name

    def test_percentile(self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp):
        """Percentile calculation should produce a DataArray with correct shape and values."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)
        new_name = "test_name"

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            new_name,
            None,
            95,
            np.array([None]),
            groupby=(1, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.DataArray)
        assert calc_val.shape == (1, num_sims, 1, 1)
        assert "simulation" in calc_val.dims
        assert "time" not in calc_val.dims
        assert "lat" in calc_val.coords and "lon" in calc_val.coords
        assert np.all(calc_val < ds.max())
        assert calc_val.name == new_name

    def test_percentile_with_non_iterable_one_in_x(
        self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp
    ):
        """Percentile should work when one_in_x is a non-iterable None."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)
        new_name = "test_name"

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            new_name,
            None,
            95,
            None,
            groupby=(1, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.DataArray)
        assert calc_val.shape == (1, num_sims, 1, 1)
        assert "simulation" in calc_val.dims
        assert "time" not in calc_val.dims
        assert "lat" in calc_val.coords and "lon" in calc_val.coords
        assert np.all(calc_val < ds.max())
        assert calc_val.name == new_name

    def test_one_in_x(self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp):
        """1-in-X return value should produce a Dataset with return_value and p_values."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            "test_name",
            None,
            None,
            np.array([10]),
            groupby=(1, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.Dataset)
        assert calc_val["return_value"].shape == (num_sims, 1)
        assert calc_val["p_values"].shape == (num_sims,)
        assert "simulation" in calc_val.dims

    def test_one_in_x_multiple_values(
        self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp
    ):
        """1-in-X with multiple return periods should produce correctly shaped output."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)
        one_in_x_vals = np.array([10, 100])

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            "test_name",
            None,
            None,
            one_in_x_vals,
            groupby=(1, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.Dataset)
        assert calc_val["return_value"].shape == (num_sims, len(one_in_x_vals))
        assert calc_val["p_values"].shape == (num_sims,)
        assert "simulation" in calc_val.dims



class TestMetricAggEventParams:
    """Tests for duration/groupby/grouped_duration parameter combinations in _metric_agg."""

    def test_duration_only(self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp):
        """1-in-X with duration only (4-hour rolling window on hourly data)."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            "test_name",
            None,
            None,
            np.array([10]),
            duration=(4, "hour"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.Dataset)
        assert calc_val["return_value"].shape == (num_sims, 1)
        assert calc_val["p_values"].shape == (num_sims,)
        assert "simulation" in calc_val.dims

    def test_groupby_and_grouped_duration(
        self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp
    ):
        """1-in-X with groupby + grouped_duration (daily max, 3-day rolling)."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            "test_name",
            None,
            None,
            np.array([10]),
            groupby=(1, "day"),
            grouped_duration=(3, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.Dataset)
        assert calc_val["return_value"].shape == (num_sims, 1)
        assert calc_val["p_values"].shape == (num_sims,)
        assert "simulation" in calc_val.dims

    def test_all_three_params(self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp):
        """1-in-X with all three: duration + groupby + grouped_duration."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            "test_name",
            None,
            None,
            np.array([10]),
            duration=(4, "hour"),
            groupby=(1, "day"),
            grouped_duration=(3, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.Dataset)
        assert calc_val["return_value"].shape == (num_sims, 1)
        assert calc_val["p_values"].shape == (num_sims,)
        assert "simulation" in calc_val.dims

    def test_all_params_unset(self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp):
        """1-in-X with all params UNSET (raw annual block maxima)."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "max",
            "test_name",
            None,
            None,
            np.array([10]),
            duration=UNSET,
            groupby=UNSET,
            grouped_duration=UNSET,
            distr="gev",
        )

        assert isinstance(calc_val, xr.Dataset)
        assert calc_val["return_value"].shape == (num_sims, 1)
        assert calc_val["p_values"].shape == (num_sims,)

    def test_groupby_grouped_duration_min(
        self, test_dataarray_time_2030_2035_wrf_3km_hourly_temp
    ):
        """1-in-X with groupby + grouped_duration using min extremes."""
        ds = test_dataarray_time_2030_2035_wrf_3km_hourly_temp.copy()
        num_sims = len(ds.simulation)

        calc_val = _metric_agg(
            ds,
            "Air Temperature at 2m",
            np.arange(1, 13),
            "time",
            "min",
            "test_name",
            None,
            None,
            np.array([10]),
            groupby=(1, "day"),
            grouped_duration=(3, "day"),
            distr="gev",
        )

        assert isinstance(calc_val, xr.Dataset)
        assert calc_val["return_value"].shape == (num_sims, 1)
        assert calc_val["p_values"].shape == (num_sims,)


### Listing out different parameters to test `cava_data` on
inputs = [
    ## WRF Time
    (
        "Air Temperature at 2m",
        "Dynamical",
        "Time",
        "Historical Climate",
        ["SSP 3-7.0"],
        False,
        1.5,
        "min",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_wrf_3km_hourly_temp",
    ),
    ### LOCA Time
    (
        "Air Temperature at 2m",
        "Statistical",
        "Time",
        "Historical Climate",
        ["SSP 3-7.0"],
        False,
        1.5,
        "max",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_loca_3km_daily_temp",
    ),
    ### WRF WL
    (
        "Air Temperature at 2m",
        "Dynamical",
        "Warming Level",
        "Historical Climate",
        ["SSP 3-7.0"],
        False,
        2.0,
        "min",
        "all",
        "calculate",
        False,
        "test_dataarray_wl_20_all_season_wrf_3km_hourly_temp",
    ),
    ### LOCA WL all seasons
    (
        "Air Temperature at 2m",
        "Statistical",
        "Warming Level",
        "Historical Climate",
        ["SSP 3-7.0"],
        False,
        2.0,
        "max",
        "all",
        "raw",
        False,
        "test_dataarray_wl_20_all_season_loca_3km_daily_temp",
    ),
    # LOCA WL summer
    (
        "Air Temperature at 2m",
        "Statistical",
        "Warming Level",
        "Historical Climate",
        ["SSP 3-7.0"],
        False,
        2.0,
        "max",
        "summer",
        "raw",
        False,
        "test_dataarray_wl_20_summer_season_loca_3km_daily_temp",
    ),
    # ## NOAA Heat Index test
    (
        "NOAA Heat Index",
        "Dynamical",
        "Time",
        "Historical Climate",
        ["SSP 3-7.0"],
        True,
        1.5,
        "min",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_wrf_3km_hourly_heat_index",
    ),
    # ### Historical Reconstruction, no batch
    # (
    #     "Air Temperature at 2m",
    #     "Dynamical",
    #     "Time",
    #     "Historical Reconstruction",
    #     ["SSP 3-7.0"],
    #     False,
    #     1.5,
    #     "max",
    #     "all",
    #     "both",
    #     False,
    #     "test_dataarray_time_2010_2015_histrecon_wrf_3km_hourly_temp_single_cell",
    # ),
    ## Historical Reconstruction, batch
    (
        "Air Temperature at 2m",
        "Dynamical",
        "Time",
        "Historical Reconstruction",
        ["SSP 3-7.0"],
        False,
        1.5,
        "max",
        "all",
        "both",
        True,
        "test_dataarray_time_2010_2015_histrecon_wrf_3km_hourly_temp_gridded_area",
    ),
    ### Precipitation test
    (
        "Precipitation (total)",
        "Dynamical",
        "Time",
        "Historical Climate",
        ["SSP 3-7.0"],
        False,
        2.0,
        "max",
        "all",
        "both",
        False,
        "test_dataarray_time_2030_2035_wrf_3km_hourly_prec",
    ),
]


class TestCavaData:
    """Tests for the `cava_data` end-to-end function."""

    @pytest.mark.parametrize(
        "variable, downscaling_method, approach, historical_data, ssp_data, wrf_bias_adjust, warming_level, metric_calc, season, export_method, batch_mode, test_dataset_fixture",
        inputs,
    )
    def test_cava_data_params(
        self,
        request,
        variable,
        downscaling_method,
        approach,
        historical_data,
        ssp_data,
        wrf_bias_adjust,
        warming_level,
        metric_calc,
        season,
        export_method,
        batch_mode,
        test_dataset_fixture,
    ):
        """
        Test the `cava_data` function under various inputs to ensure it
        returns correctly structured output data for different parameters.

        This test covers a variety of scenarios based on downscaling methods, historical data types,
        approaches, batch mode, variables, and seasonality. It performs assertions on data shapes,
        names, and values based on the inputs, verifies both raw and calculated outputs
        and checks export configurations.
        """
        test_dataset = request.getfixturevalue(test_dataset_fixture)

        with (
            patch(
                "climakitae.core.data_interface.DataParameters.retrieve",
                return_value=test_dataset,
            ),
            patch("climakitae.explore.vulnerability._export_no_e", return_value=None),
            patch("builtins.input", return_value="y"),
        ):
            input_locations = pd.DataFrame(
                {"lat": [35.43424, 35.4], "lon": [-119.05524, -119.02176]}
            )

            batch = 2 if batch_mode else 1

            match historical_data:
                case "Historical Climate":
                    start_year, end_year = 2030, 2035
                case "Historical Reconstruction":
                    start_year, end_year = 2010, 2015

            result = cava_data(
                ## Set-up
                input_locations.iloc[:batch],  # select a single location
                time_start_year=start_year,
                time_end_year=end_year,
                warming_level=warming_level,
                downscaling_method=downscaling_method,  # WRF data
                approach=approach,
                historical_data=historical_data,
                ssp_data=ssp_data,
                wrf_bias_adjust=False,  # return all WRF models
                batch_mode=batch_mode,
                ## Likely seaonal event specific arguments
                variable=variable,
                metric_calc=metric_calc,  # daily high temperature
                percentile=75,  # likeliness percentile
                season=season,  # season
                units="degF",  # change units
                ## Export
                export_method="both",  # export only calculated metric data
                file_format="NetCDF",
            )

            def check_raw_output(result):
                days_by_season = {
                    "winter": 90,
                    "summer": 92,
                    "all": 365,
                }
                assert "raw_data" in result
                raw_res = result["raw_data"]
                match (downscaling_method, approach):
                    case ("Dynamical", "Time"):
                        if historical_data == "Historical Reconstruction":
                            assert raw_res.shape == (
                                (end_year - start_year + 1)
                                * days_by_season[season]
                                * 24,
                                batch,
                            )  # Finding the total number of hours after filtering for specific seasons
                        elif wrf_bias_adjust == True:
                            num_sims = 5 * batch
                            assert raw_res.shape == (
                                1,
                                num_sims,
                                (end_year - start_year + 1)
                                * days_by_season[season]
                                * 24,
                            )  # Finding the total number of hours after filtering for specific seasons
                        elif wrf_bias_adjust == False:
                            num_sims = 8 * batch
                            assert raw_res.shape == (
                                1,
                                num_sims,
                                (end_year - start_year + 1)
                                * days_by_season[season]
                                * 24,
                            )  # Finding the total number of hours after filtering for specific seasons
                        assert raw_res.name == variable
                    case ("Dynamical", "Warming Level"):
                        assert raw_res.shape == (
                            1,
                            8 * batch,
                            30
                            * days_by_season[season]
                            * 24,  # Pre-determined as 30-year WL slices; finding the total number of hours
                        )
                        assert raw_res.name == variable
                    case ("Statistical", "Time"):
                        assert raw_res.shape == (
                            1,
                            62 * batch,
                            (end_year - start_year + 1) * days_by_season[season],
                        )  # Finding the total number of hours after filtering for specific seasons
                        # Make sure that raw dataset pulls the correct, re-defined LOCA variable for `Air Temperature at 2m`
                        if metric_calc == "max" and variable == "Air Temperature at 2m":
                            assert raw_res.name == "Maximum air temperature at 2m"
                        elif (
                            metric_calc == "min" and variable == "Air Temperature at 2m"
                        ):
                            assert raw_res.name == "Minimum air temperature at 2m"
                    case ("Statistical", "Warming Level"):
                        assert raw_res.shape == (
                            1,
                            30
                            * days_by_season[
                                season
                            ],  # Pre-determined as 30-year WL slices; finding the total number of days
                            129 * batch,
                        )
                        # Make sure that raw dataset pulls the correct, re-defined LOCA variable for `Air Temperature at 2m`
                        if metric_calc == "max" and variable == "Air Temperature at 2m":
                            assert raw_res.name == "Maximum air temperature at 2m"
                        elif (
                            metric_calc == "min" and variable == "Air Temperature at 2m"
                        ):
                            assert raw_res.name == "Minimum air temperature at 2m"

            def check_calculate_output(result):
                assert "calc_data" in result
                calc_res = result["calc_data"]
                # Check for shape and coords depending on downscaling method
                match downscaling_method:
                    case "Dynamical":
                        if (
                            approach == "Time"
                            and historical_data != "Historical Reconstruction"
                        ):
                            if ssp_data == ["SSP 3-7.0"]:
                                assert (
                                    calc_res.scenario.item() == "Historical + SSP 3-7.0"
                                )
                        if historical_data == "Historical Reconstruction":
                            assert calc_res.shape == (1 * batch,)
                        elif not wrf_bias_adjust:
                            assert calc_res.shape == (1, 8 * batch)
                        elif wrf_bias_adjust:
                            assert calc_res.shape == (1, 5 * batch)
                        assert calc_res.frequency == "hourly"
                        if not batch_mode:
                            assert np.isclose(calc_res.lat.item(), 35.43, atol=0.02)
                            assert np.isclose(calc_res.lon.item(), -119.04, atol=0.02)
                            assert np.isclose(calc_res.x.item(), -4089113.66, atol=5000)
                            assert np.isclose(calc_res.y.item(), 1012911.12, atol=5000)
                        else:
                            assert np.all(
                                np.isclose(
                                    calc_res.lat, [35.445045, 35.400005], atol=0.1
                                )
                            )
                            assert np.all(
                                np.isclose(
                                    calc_res.lon, [-119.06061, -119.02176], atol=0.1
                                )
                            )
                            assert np.all(
                                np.isclose(
                                    calc_res.x,
                                    [-4089113.66186097, -4089113.66186097],
                                    atol=5000,
                                )
                            )
                            assert np.all(
                                np.isclose(
                                    calc_res.y,
                                    [1015911.73069854, 1009911.73069854],
                                    atol=5000,
                                )
                            )
                    case "Statistical":
                        if (
                            approach == "Time"
                            and historical_data != "Historical Reconstruction"
                        ):
                            if ssp_data == ["SSP 3-7.0"]:
                                assert (
                                    calc_res.scenario.item() == "Historical + SSP 3-7.0"
                                )
                            assert calc_res.shape == (1, 62)
                        elif approach == "Warming Level":
                            assert calc_res.shape == (1, 129)
                        assert calc_res.frequency == "daily"
                        assert np.isclose(calc_res.lat.item(), 35.42, atol=0.01)
                        assert np.isclose(calc_res.lon.item(), -119.05, atol=0.01)

                assert calc_res.resolution == "3 km"
                if (
                    calc_res.variable_id == "t2"
                    or calc_res.variable_id == "tasmax"
                    or calc_res.variable_id == "noaa_heat_index_derived"
                ):
                    assert calc_res.units == "degF"
                elif calc_res.variable_id == "prec":
                    assert calc_res.units == "inches"
                assert calc_res.percentile.item() == 75

            # Check for appropriate data structures
            assert isinstance(result, dict)

            match export_method:
                case "raw":
                    check_raw_output(result)
                case "calculate":
                    check_calculate_output(result)
                case "both":
                    check_raw_output(result)
                    check_calculate_output(result)
